{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "573e52c4-8e3d-448f-b94b-3ab825cb6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import wave\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "import webrtcvad\n",
    "from pydub import AudioSegment, silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37204fd5-2044-4b1c-bb00-1227a2424fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_flac_files(\n",
    "    input_folder: str,\n",
    "    output_folder: str,\n",
    "    min_silence_len: int = 400,\n",
    "    silence_thresh: int = -50,\n",
    "    keep_silence: int = 200,\n",
    "    vad_aggressiveness: int = 3,\n",
    "    target_sr: int = 16000\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a two-level folder structure of FLAC files:\n",
    "      - Splits on silence,\n",
    "      - (Optionally) applies WebRTC Voice Activity Detection,\n",
    "      - Noise reduction,\n",
    "      - Volume normalization,\n",
    "      - Resamples to target_sr,\n",
    "      - Saves the processed audio with the same folder structure.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Root directory containing user folders (1..150).\n",
    "        output_folder (str): Where to save processed files (mirroring structure).\n",
    "        min_silence_len (int): Minimum length of silence (ms) for pydub splitting.\n",
    "        silence_thresh (int): Silence threshold in dBFS for pydub.\n",
    "        keep_silence (int): How many ms of silence to keep at each split edge.\n",
    "        vad_aggressiveness (int): 0-3 (webrtcvad aggressiveness; higher = more aggressive).\n",
    "        target_sr (int): Target sample rate for final audio.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate over each user folder (e.g. \"1\", \"2\", ..., \"150\")\n",
    "    for user_dir in os.listdir(input_folder):\n",
    "        user_input_path = os.path.join(input_folder, user_dir)\n",
    "        if not os.path.isdir(user_input_path):\n",
    "            continue  # skip anything that's not a directory\n",
    "\n",
    "        # Create matching directory in the output folder\n",
    "        user_output_path = os.path.join(output_folder, user_dir)\n",
    "        os.makedirs(user_output_path, exist_ok=True)\n",
    "\n",
    "        # Process each .flac file in this user's folder\n",
    "        for filename in os.listdir(user_input_path):\n",
    "            if filename.lower().endswith(\".flac\"):\n",
    "                file_path = os.path.join(user_input_path, filename)\n",
    "                \n",
    "                # -------------------------------------------------\n",
    "                # 1) READ FLAC with pydub as AudioSegment\n",
    "                # -------------------------------------------------\n",
    "                audio_segment = AudioSegment.from_file(file_path, format=\"flac\")\n",
    "                print(f\"Loaded: {file_path} [dBFS={audio_segment.dBFS:.2f}]\")\n",
    "\n",
    "                # -------------------------------------------------\n",
    "                # 2) SPLIT BY SILENCE (pydub)\n",
    "                # -------------------------------------------------\n",
    "                # This splits the audio into chunks where each chunk is separated\n",
    "                # by >= min_silence_len ms of silence at < silence_thresh dBFS.\n",
    "                # keep_silence (ms) keeps a bit of silence at edges for continuity.\n",
    "                chunks = silence.split_on_silence(\n",
    "                    audio_segment,\n",
    "                    min_silence_len=min_silence_len,\n",
    "                    silence_thresh=silence_thresh,\n",
    "                    keep_silence=keep_silence\n",
    "                )\n",
    "\n",
    "                # If no chunks found (completely silent?), just treat the entire file as one chunk\n",
    "                if not chunks:\n",
    "                    chunks = [audio_segment]\n",
    "\n",
    "                # -------------------------------------------------\n",
    "                # 3) PROCESS EACH CHUNK\n",
    "                # -------------------------------------------------\n",
    "                for i, chunk in enumerate(chunks, start=1):\n",
    "                    # (Optional) Convert chunk to PCM for WebRTC VAD\n",
    "                    # Note: pydub chunk sample_width might be 2 or 4 bytes, etc.\n",
    "                    # We need 16-bit PCM for webrtcvad, with sample rates 8k, 16k, 32k, or 48k.\n",
    "                    chunk_frame_rate = chunk.frame_rate\n",
    "                    chunk = chunk.set_frame_rate(target_sr).set_channels(1).set_sample_width(2)\n",
    "                    chunk_frame_rate = chunk.frame_rate  # Now should be target_sr\n",
    "\n",
    "                    # Optionally run WebRTC VAD to further trim non-speech\n",
    "                    # If your data is already well-split by silence, you can skip this step.\n",
    "                    chunk = apply_webrtc_vad(chunk, vad_aggressiveness)\n",
    "\n",
    "                    # Skip empty chunks after VAD\n",
    "                    if len(chunk) < 10:  \n",
    "                        continue\n",
    "\n",
    "                    # Convert chunk (pydub) back to numpy for noisereduce + librosa\n",
    "                    raw_samples = chunk.raw_data\n",
    "                    audio_data, _ = sf.read(io.BytesIO(raw_samples), dtype='float32')\n",
    "                    \n",
    "                    # -------------------------------------------------\n",
    "                    # 4) NOISE REDUCTION (noisereduce)\n",
    "                    # -------------------------------------------------\n",
    "                    reduced_audio = nr.reduce_noise(y=audio_data, sr=target_sr)\n",
    "\n",
    "                    # -------------------------------------------------\n",
    "                    # 5) VOLUME NORMALIZATION (librosa)\n",
    "                    # -------------------------------------------------\n",
    "                    normalized_audio = librosa.util.normalize(reduced_audio)\n",
    "\n",
    "                    # -------------------------------------------------\n",
    "                    # 6) RESAMPLE to target_sr (already at target_sr, but just in case)\n",
    "                    # -------------------------------------------------\n",
    "                    # If you want to absolutely ensure sampling rate:\n",
    "                    final_audio = librosa.resample(\n",
    "                        normalized_audio, \n",
    "                        orig_sr=target_sr, \n",
    "                        target_sr=target_sr\n",
    "                    )\n",
    "\n",
    "                    # -------------------------------------------------\n",
    "                    # 7) SAVE the processed chunk\n",
    "                    # -------------------------------------------------\n",
    "                    base_name = os.path.splitext(filename)[0]  # e.g. audio_1\n",
    "                    output_filename = f\"{base_name}_chunk_{i}_cleaned.wav\"\n",
    "                    output_file_path = os.path.join(user_output_path, output_filename)\n",
    "\n",
    "                    sf.write(output_file_path, final_audio, target_sr)\n",
    "                    print(f\"  -> Saved chunk {i}: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cae8e43-7513-4011-adb4-0b529b2fe649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_webrtc_vad(audio_segment: AudioSegment, aggressiveness: int = 3) -> AudioSegment:\n",
    "    \"\"\"\n",
    "    Applies WebRTC VAD to a mono, 16-bit AudioSegment at 8/16/32/48 kHz.\n",
    "    Trims out frames flagged as non-voice. \n",
    "    Returns a smaller AudioSegment containing only voiced frames.\n",
    "\n",
    "    NOTE: pydub's chunk must already be set to 16-bit, 1 channel, \n",
    "    and a supported sample rate before calling this function.\n",
    "    \"\"\"\n",
    "    vad = webrtcvad.Vad()\n",
    "    vad.set_mode(aggressiveness)\n",
    "\n",
    "    sample_rate = audio_segment.frame_rate\n",
    "    raw_data = audio_segment.raw_data\n",
    "    bytes_per_frame = 2  # since we set sample_width=2\n",
    "\n",
    "    # WebRTC VAD expects frames of 10, 20, or 30 ms\n",
    "    frame_ms = 30  \n",
    "    frame_size = int(sample_rate * (frame_ms / 1000.0))  # samples per frame\n",
    "\n",
    "    voiced_frames = bytearray()\n",
    "\n",
    "    # Process the raw_data in chunks of 'frame_size * bytes_per_frame'\n",
    "    for start in range(0, len(raw_data), frame_size * bytes_per_frame):\n",
    "        end = start + (frame_size * bytes_per_frame)\n",
    "        if end > len(raw_data):\n",
    "            break\n",
    "        frame = raw_data[start:end]\n",
    "        # VAD check\n",
    "        is_speech = vad.is_speech(frame, sample_rate)\n",
    "        if is_speech:\n",
    "            voiced_frames.extend(frame)\n",
    "\n",
    "    # Build a new AudioSegment from the voiced frames\n",
    "    voiced_segment = AudioSegment(\n",
    "        data=bytes(voiced_frames),\n",
    "        sample_width=audio_segment.sample_width,\n",
    "        frame_rate=sample_rate,\n",
    "        channels=1\n",
    "    )\n",
    "    return voiced_segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c35b4e39-6a08-4f94-b0a7-dfd84c9c0491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: C:\\Users\\VICTUS\\Voice\\A Dataset for Voice-Based Human Identity Recognition\\differentPhrase\\1\\1-11.flac [dBFS=-26.00]\n"
     ]
    },
    {
     "ename": "LibsndfileError",
     "evalue": "Error opening <_io.BytesIO object at 0x000002248FD2C720>: Format not recognised.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVICTUS\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVoice\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mA Dataset for Voice-Based Human Identity Recognition\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdifferentPhrase\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m      3\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVICTUS\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVoice\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mA Dataset for Voice-Based Human Identity Recognition\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mpreprocess_flac_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_silence_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pydub: ms of silence\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilence_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# pydub: dBFS threshold\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_silence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# pydub: keep 200ms\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvad_aggressiveness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# webrtcvad: 0-3\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# final sample rate\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 58\u001b[0m, in \u001b[0;36mpreprocess_flac_files\u001b[1;34m(input_folder, output_folder, min_silence_len, silence_thresh, keep_silence, vad_aggressiveness, target_sr)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     57\u001b[0m raw_samples \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mraw_data\n\u001b[1;32m---> 58\u001b[0m audio_data, _ \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m reduced_audio \u001b[38;5;241m=\u001b[39m nr\u001b[38;5;241m.\u001b[39mreduce_noise(y\u001b[38;5;241m=\u001b[39maudio_data, sr\u001b[38;5;241m=\u001b[39mtarget_sr)\n\u001b[0;32m     60\u001b[0m normalized_audio \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mnormalize(reduced_audio)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\voiceauth\\lib\\site-packages\\soundfile.py:305\u001b[0m, in \u001b[0;36mread\u001b[1;34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(file, frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, always_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    220\u001b[0m          fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, samplerate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m          \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, subtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, endian\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    222\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Provide audio data from a sound file as NumPy array.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m    By default, the whole file is read from the beginning, but the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    303\u001b[0m \n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msubtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    307\u001b[0m         frames \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39m_prepare_read(start, stop, frames)\n\u001b[0;32m    308\u001b[0m         data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(frames, dtype, always_2d, fill_value, out)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\voiceauth\\lib\\site-packages\\soundfile.py:690\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bitrate_mode \u001b[38;5;241m=\u001b[39m bitrate_mode\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    689\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\voiceauth\\lib\\site-packages\\soundfile.py:1265\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_ptr \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mNULL:\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;66;03m# get the actual error code\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mframes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening <_io.BytesIO object at 0x000002248FD2C720>: Format not recognised."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_folder = r\"C:\\Users\\VICTUS\\Voice\\A Dataset for Voice-Based Human Identity Recognition\\differentPhrase\" \n",
    "    output_folder = r\"C:\\Users\\VICTUS\\Voice\\A Dataset for Voice-Based Human Identity Recognition\\output\"\n",
    "    \n",
    "    preprocess_flac_files(\n",
    "        input_folder=input_folder,\n",
    "        output_folder=output_folder,\n",
    "        min_silence_len=400,    # pydub: ms of silence\n",
    "        silence_thresh=-50,     # pydub: dBFS threshold\n",
    "        keep_silence=200,       # pydub: keep 200ms\n",
    "        vad_aggressiveness=3,   # webrtcvad: 0-3\n",
    "        target_sr=16000         # final sample rate\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3ab8a6-2b97-4dcd-ab90-f7122efa4158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
